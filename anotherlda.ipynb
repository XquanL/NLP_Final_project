{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from torchnlp.encoders.text import WhitespaceEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics =pd.read_csv('https://raw.githubusercontent.com/tashapiro/predicting-song-music-genre/main/data/lyrics_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOJI_REGEX = re.compile(\n",
    "    \"([\"\n",
    "    \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "    \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "    \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "    \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "    \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "    \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "    \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "    \"\\U000024C2-\\U0001F251\"\n",
    "    \"])\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re.compile('([üåÄ-üóøüòÄ-üôèüöÄ-\\U0001f6ffüúÄ-\\U0001f77füûÄ-\\U0001f7ffü†Ä-\\U0001f8ffü§Ä-üßøü®Ä-\\U0001fa6fü©∞-\\U0001faff‚úÇ-‚û∞‚ìÇ-üâë])')\n"
     ]
    }
   ],
   "source": [
    "print(EMOJI_REGEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove puntuation\n",
    "lyrics['final_lyrics'] = lyrics['cleaned_lyrics'].map(lambda x : re.sub(r\"\"\"[!\"#\\$%&'\\(\\)\\*\\+,-\\./:;\\<=\\>?\\[\\]\\^_`\\{\\|\\}~‚Äú‚Äù‚Äô]\"\"\", '', x))\n",
    "#lower case\n",
    "lyrics['final_lyrics'] = lyrics['final_lyrics'].map(lambda x: x.lower())\n",
    "#remove emoji\n",
    "lyrics['final_lyrics'] = lyrics['final_lyrics'].str.replace(\n",
    "        EMOJI_REGEX, r\" \\1 \", regex=True\n",
    "    ) \n",
    "#remove double space\n",
    "lyrics['final_lyrics'] = lyrics[\"final_lyrics\"].str.replace(r\"\\s+\", \" \", regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>final_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>country</td>\n",
       "      <td>every time our eyes meet this feeling inside m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>country</td>\n",
       "      <td>when the sun goes down on my side of town that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>country</td>\n",
       "      <td>it was seven hundred fence posts from your pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>country</td>\n",
       "      <td>kelsea ballerini dibs dolly parton jolene clar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>country</td>\n",
       "      <td>something bout the way shes wearing her dress ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     genre                                       final_lyrics\n",
       "0  country  every time our eyes meet this feeling inside m...\n",
       "1  country  when the sun goes down on my side of town that...\n",
       "2  country  it was seven hundred fence posts from your pla...\n",
       "3  country  kelsea ballerini dibs dolly parton jolene clar...\n",
       "4  country  something bout the way shes wearing her dress ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = lyrics.loc[:,['genre','final_lyrics']]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize\n",
    " remove inflectional endings only and to return the base or dictionary form of a word,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(lyrics):\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    lyrics_str=word_tokenize(lyrics)\n",
    "    new_words = []\n",
    "    for word in lyrics_str:\n",
    "        new_words.append(lemmatizer.lemmatize(word))\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "df[\"ly\"] = df[\"final_lyrics\"].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using nltk to remove stop words\n",
    "Stop words are common words like ‚Äòthe‚Äô, ‚Äòand‚Äô, ‚ÄòI‚Äô, etc. that are very frequent in text, and so don‚Äôt convey insights into the specific topic of a document. We can remove these stop words from the text in a given corpus to clean up the data, and identify words that are more rare and potentially more relevant to what we‚Äôre interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['oh','ohh'])\n",
    "rm_words = set(stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"rm_ly\"] = df[\"ly\"].str.split().apply(lambda x: \" \".join(word for word in x if word not in rm_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>final_lyrics</th>\n",
       "      <th>ly</th>\n",
       "      <th>rm_ly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>country</td>\n",
       "      <td>every time our eyes meet this feeling inside m...</td>\n",
       "      <td>every time our eye meet this feeling inside me...</td>\n",
       "      <td>every time eye meet feeling inside almost take...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>country</td>\n",
       "      <td>when the sun goes down on my side of town that...</td>\n",
       "      <td>when the sun go down on my side of town that l...</td>\n",
       "      <td>sun go side town lonesome feelin come door who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>country</td>\n",
       "      <td>it was seven hundred fence posts from your pla...</td>\n",
       "      <td>it wa seven hundred fence post from your place...</td>\n",
       "      <td>wa seven hundred fence post place neither one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>country</td>\n",
       "      <td>kelsea ballerini dibs dolly parton jolene clar...</td>\n",
       "      <td>kelsea ballerini dibs dolly parton jolene clar...</td>\n",
       "      <td>kelsea ballerini dibs dolly parton jolene clar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>country</td>\n",
       "      <td>something bout the way shes wearing her dress ...</td>\n",
       "      <td>something bout the way shes wearing her dress ...</td>\n",
       "      <td>something bout way shes wearing dress little t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     genre                                       final_lyrics  \\\n",
       "0  country  every time our eyes meet this feeling inside m...   \n",
       "1  country  when the sun goes down on my side of town that...   \n",
       "2  country  it was seven hundred fence posts from your pla...   \n",
       "3  country  kelsea ballerini dibs dolly parton jolene clar...   \n",
       "4  country  something bout the way shes wearing her dress ...   \n",
       "\n",
       "                                                  ly  \\\n",
       "0  every time our eye meet this feeling inside me...   \n",
       "1  when the sun go down on my side of town that l...   \n",
       "2  it wa seven hundred fence post from your place...   \n",
       "3  kelsea ballerini dibs dolly parton jolene clar...   \n",
       "4  something bout the way shes wearing her dress ...   \n",
       "\n",
       "                                               rm_ly  \n",
       "0  every time eye meet feeling inside almost take...  \n",
       "1  sun go side town lonesome feelin come door who...  \n",
       "2  wa seven hundred fence post place neither one ...  \n",
       "3  kelsea ballerini dibs dolly parton jolene clar...  \n",
       "4  something bout way shes wearing dress little t...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert genre to category and rm_ly to string\n",
    "#df.rm_ly = df.rm_ly.astype(\"string\")\n",
    "#df.genre = df.genre.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3420 entries, 0 to 3419\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   genre         3420 non-null   object\n",
      " 1   final_lyrics  3420 non-null   object\n",
      " 2   ly            3420 non-null   object\n",
      " 3   rm_ly         3420 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 107.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(\n",
    "    df[\"rm_ly\"].to_frame(), df[\"genre\"], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2736, 1)\n",
      "(684, 1)\n"
     ]
    }
   ],
   "source": [
    "for x_ in (xtrain, xtest):\n",
    "    print(x_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def whitespace_encode(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    #input_ = df[\"rm_ly\"].tolist()\n",
    "    #encoder = WhitespaceEncoder(input_, min_occurrences=2)\n",
    "    #encoded_data = [encoder.encode(example) for example in input_]\n",
    "    #with open(\"../encoder.pickle\", \"wb\") as file:\n",
    "        #joblib.dump(encoder, file)\n",
    "    #print(\"Saved encoder to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = whitespace_encode(xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize data and fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'encoder.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#load encoder\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mencoder.pickle\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     encoder: WhitespaceEncoder \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(f)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'encoder.pickle'"
     ]
    }
   ],
   "source": [
    "#load encoder\n",
    "with open(\"encoder.pickle\", \"rb\") as f:\n",
    "    encoder: WhitespaceEncoder = joblib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rm_ly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>dont need education dont need thought control ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>want hang youve got take cocaine want get grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>livin moonlight lookin hill hill dont shine ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>fuck steve harvey life game wan na play counti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>dirty old part city sun refused shine people t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>lp come word bond people said couldnt happen c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>home dont play game j cause youll see sideline...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>butterfly searching relax pulling jazz stack c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>fuck bitch get money fuck nigga get money fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>lizzo rumor feat cardi b pinkpantheress machin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2736 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  rm_ly\n",
       "1621  dont need education dont need thought control ...\n",
       "2084  want hang youve got take cocaine want get grou...\n",
       "2177  livin moonlight lookin hill hill dont shine ri...\n",
       "871   fuck steve harvey life game wan na play counti...\n",
       "2398  dirty old part city sun refused shine people t...\n",
       "...                                                 ...\n",
       "1095  lp come word bond people said couldnt happen c...\n",
       "1130  home dont play game j cause youll see sideline...\n",
       "1294  butterfly searching relax pulling jazz stack c...\n",
       "860   fuck bitch get money fuck nigga get money fuck...\n",
       "3174  lizzo rumor feat cardi b pinkpantheress machin...\n",
       "\n",
       "[2736 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input= xtrain['rm_ly'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=4, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(n_components=4, n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(n_components=4, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "xtrain_matrix = cv.fit_transform(input)\n",
    "xtest_matrix = cv.transform(xtest)\n",
    "lda = LatentDirichletAllocation(n_components=4, random_state=42, n_jobs=-1)\n",
    "lda.fit(xtrain_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['007',\n",
       " '01101001',\n",
       " '02',\n",
       " '03',\n",
       " '04',\n",
       " '06',\n",
       " '07',\n",
       " '070',\n",
       " '08',\n",
       " '09',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '10000',\n",
       " '100000',\n",
       " '1000000',\n",
       " '1005',\n",
       " '100k',\n",
       " '100x',\n",
       " '101',\n",
       " '1010',\n",
       " '102',\n",
       " '104',\n",
       " '105',\n",
       " '106',\n",
       " '108',\n",
       " '108th',\n",
       " '109',\n",
       " '10k',\n",
       " '10kcaash',\n",
       " '10ll',\n",
       " '10th',\n",
       " '11',\n",
       " '110',\n",
       " '1111',\n",
       " '112',\n",
       " '1124',\n",
       " '1130',\n",
       " '1145',\n",
       " '115',\n",
       " '116',\n",
       " '117embed',\n",
       " '11embed',\n",
       " '11phenyl',\n",
       " '12',\n",
       " '120embed',\n",
       " '122embed',\n",
       " '123',\n",
       " '1230',\n",
       " '1234',\n",
       " '125',\n",
       " '125th',\n",
       " '127',\n",
       " '129',\n",
       " '12embed',\n",
       " '12gauge',\n",
       " '12k',\n",
       " '12th',\n",
       " '13',\n",
       " '131',\n",
       " '133embed',\n",
       " '1365',\n",
       " '13embed',\n",
       " '13kembed',\n",
       " '13th',\n",
       " '13x',\n",
       " '14',\n",
       " '144000',\n",
       " '149',\n",
       " '14embed',\n",
       " '14k',\n",
       " '15',\n",
       " '151',\n",
       " '155',\n",
       " '15embed',\n",
       " '15th',\n",
       " '16',\n",
       " '165',\n",
       " '16embed',\n",
       " '16k',\n",
       " '17',\n",
       " '1718',\n",
       " '175embed',\n",
       " '17embed',\n",
       " '17yearold',\n",
       " '18',\n",
       " '180',\n",
       " '1800',\n",
       " '18002738255',\n",
       " '1800j√≥dete',\n",
       " '1800seeya',\n",
       " '1806',\n",
       " '182',\n",
       " '1830',\n",
       " '185',\n",
       " '187',\n",
       " '1870',\n",
       " '1895',\n",
       " '18embed',\n",
       " '18th',\n",
       " '18wheeler',\n",
       " '18wheelers',\n",
       " '19',\n",
       " '1900mixalot',\n",
       " '1916',\n",
       " '1922',\n",
       " '1923',\n",
       " '1930',\n",
       " '1942',\n",
       " '1950',\n",
       " '1951',\n",
       " '1953',\n",
       " '1960s',\n",
       " '1962',\n",
       " '1965',\n",
       " '1966',\n",
       " '1967s',\n",
       " '1968',\n",
       " '1969',\n",
       " '1969dan',\n",
       " '19701',\n",
       " '1970s',\n",
       " '1971',\n",
       " '1973',\n",
       " '1974',\n",
       " '1975',\n",
       " '1976',\n",
       " '1979',\n",
       " '1980',\n",
       " '1980s',\n",
       " '1981',\n",
       " '1983',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1987',\n",
       " '1988',\n",
       " '1989',\n",
       " '1990',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1995',\n",
       " '1995motives',\n",
       " '1996',\n",
       " '1998',\n",
       " '1999',\n",
       " '19embed',\n",
       " '19th',\n",
       " '1embed',\n",
       " '1k',\n",
       " '1nonly',\n",
       " '1st',\n",
       " '1train',\n",
       " '1x',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2000embed',\n",
       " '2000whatever',\n",
       " '2001',\n",
       " '2002',\n",
       " '2003',\n",
       " '2004',\n",
       " '2004a',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007rudy',\n",
       " '2009',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '2013',\n",
       " '2014',\n",
       " '2015',\n",
       " '2015s',\n",
       " '2016',\n",
       " '2016s',\n",
       " '2017',\n",
       " '2018',\n",
       " '2019',\n",
       " '201embed',\n",
       " '2020',\n",
       " '2021',\n",
       " '203',\n",
       " '204',\n",
       " '2049',\n",
       " '2055',\n",
       " '2064217',\n",
       " '20k',\n",
       " '20ks',\n",
       " '20th',\n",
       " '21',\n",
       " '212',\n",
       " '213',\n",
       " '214',\n",
       " '215',\n",
       " '215embed',\n",
       " '218embed',\n",
       " '219',\n",
       " '21embed',\n",
       " '21st',\n",
       " '22',\n",
       " '220',\n",
       " '223s',\n",
       " '225',\n",
       " '227',\n",
       " '227embed',\n",
       " '229',\n",
       " '22gz',\n",
       " '22nd',\n",
       " '23',\n",
       " '230',\n",
       " '235',\n",
       " '236',\n",
       " '238',\n",
       " '23rd',\n",
       " '24',\n",
       " '240',\n",
       " '244',\n",
       " '245',\n",
       " '247',\n",
       " '24heavy',\n",
       " '24kgoldn',\n",
       " '25',\n",
       " '253',\n",
       " '259',\n",
       " '25th',\n",
       " '26',\n",
       " '26inch',\n",
       " '27',\n",
       " '27embed',\n",
       " '28',\n",
       " '280s',\n",
       " '28th',\n",
       " '2econd2ight2eer',\n",
       " '2embed',\n",
       " '2g',\n",
       " '2honest',\n",
       " '2kbaby',\n",
       " '2late',\n",
       " '2little',\n",
       " '2loves',\n",
       " '2na',\n",
       " '2nafish',\n",
       " '2nd',\n",
       " '2pac',\n",
       " '2step',\n",
       " '2wei',\n",
       " '2x',\n",
       " '2xembed',\n",
       " '2yan',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '303',\n",
       " '3030',\n",
       " '30embed',\n",
       " '30hertz',\n",
       " '30k',\n",
       " '31',\n",
       " '310',\n",
       " '311',\n",
       " '313',\n",
       " '315',\n",
       " '316',\n",
       " '31embed',\n",
       " '32',\n",
       " '320',\n",
       " '324',\n",
       " '327s',\n",
       " '32embed',\n",
       " '33',\n",
       " '330',\n",
       " '330ish',\n",
       " '33yearold',\n",
       " '34',\n",
       " '343',\n",
       " '345trimethoxyphenethylamine',\n",
       " '347aidan',\n",
       " '348',\n",
       " '34embed',\n",
       " '34methylenedioxymethamphetamine',\n",
       " '35',\n",
       " '3500',\n",
       " '353',\n",
       " '359embed',\n",
       " '35embed',\n",
       " '36',\n",
       " '360',\n",
       " '362436',\n",
       " '362534',\n",
       " '365',\n",
       " '369',\n",
       " '36embed',\n",
       " '38',\n",
       " '380',\n",
       " '380s',\n",
       " '38embed',\n",
       " '38th',\n",
       " '39embed',\n",
       " '3am',\n",
       " '3braid',\n",
       " '3d',\n",
       " '3embed',\n",
       " '3hunna',\n",
       " '3methylmorphine',\n",
       " '3piece',\n",
       " '3rd',\n",
       " '3somethin',\n",
       " '3wheel',\n",
       " '3wheeling',\n",
       " '3x',\n",
       " '40',\n",
       " '400',\n",
       " '4000',\n",
       " '40000',\n",
       " '400450',\n",
       " '409',\n",
       " '40ounce',\n",
       " '40water',\n",
       " '41',\n",
       " '411',\n",
       " '415s',\n",
       " '41embed',\n",
       " '42',\n",
       " '420',\n",
       " '429embed',\n",
       " '43',\n",
       " '430',\n",
       " '435',\n",
       " '44',\n",
       " '441',\n",
       " '442',\n",
       " '44phantom',\n",
       " '44s',\n",
       " '45',\n",
       " '45s',\n",
       " '45ths',\n",
       " '46',\n",
       " '47',\n",
       " '47embed',\n",
       " '47th',\n",
       " '48',\n",
       " '49',\n",
       " '491embed',\n",
       " '49th',\n",
       " '4am',\n",
       " '4embed',\n",
       " '4ever',\n",
       " '4h',\n",
       " '4l',\n",
       " '4th',\n",
       " '4tro',\n",
       " '4wheel',\n",
       " '4x',\n",
       " '4x2embed',\n",
       " '4x3embed',\n",
       " '4x4',\n",
       " '4x4embed',\n",
       " '50',\n",
       " '500',\n",
       " '5000',\n",
       " '50000',\n",
       " '5001',\n",
       " '5011',\n",
       " '505',\n",
       " '5050',\n",
       " '50k',\n",
       " '50landing',\n",
       " '51',\n",
       " '515',\n",
       " '516',\n",
       " '52',\n",
       " '52embed',\n",
       " '53',\n",
       " '537',\n",
       " '54',\n",
       " '545',\n",
       " '55',\n",
       " '551embed',\n",
       " '55th',\n",
       " '560',\n",
       " '57',\n",
       " '58embed',\n",
       " '59',\n",
       " '59doubleo',\n",
       " '5am',\n",
       " '5am2embed',\n",
       " '5embed',\n",
       " '5ft',\n",
       " '5ing',\n",
       " '5k',\n",
       " '5star',\n",
       " '5th',\n",
       " '60',\n",
       " '600',\n",
       " '6040',\n",
       " '610',\n",
       " '624',\n",
       " '626',\n",
       " '626embed',\n",
       " '63',\n",
       " '634',\n",
       " '64',\n",
       " '65',\n",
       " '650',\n",
       " '664',\n",
       " '666',\n",
       " '67',\n",
       " '68',\n",
       " '685',\n",
       " '69',\n",
       " '6930embed',\n",
       " '69ed',\n",
       " '6embed',\n",
       " '6ix9ine',\n",
       " '6lack',\n",
       " '6th',\n",
       " '6x',\n",
       " '70',\n",
       " '700',\n",
       " '7071',\n",
       " '711',\n",
       " '715',\n",
       " '730',\n",
       " '735',\n",
       " '737',\n",
       " '74',\n",
       " '740',\n",
       " '745',\n",
       " '75',\n",
       " '760',\n",
       " '76embed',\n",
       " '76er',\n",
       " '77',\n",
       " '777',\n",
       " '7a',\n",
       " '7eleven',\n",
       " '7embed',\n",
       " '7even',\n",
       " '7up',\n",
       " '7xl',\n",
       " '80',\n",
       " '800',\n",
       " '800db',\n",
       " '808',\n",
       " '808s',\n",
       " '80deca',\n",
       " '815',\n",
       " '82',\n",
       " '83',\n",
       " '832',\n",
       " '84',\n",
       " '84s',\n",
       " '85',\n",
       " '85207700900781',\n",
       " '85er',\n",
       " '86',\n",
       " '8616',\n",
       " '87',\n",
       " '8701',\n",
       " '88',\n",
       " '88rising',\n",
       " '89',\n",
       " '8ball',\n",
       " '8bar',\n",
       " '8embed',\n",
       " '8th',\n",
       " '8track',\n",
       " '8yearolds',\n",
       " '90',\n",
       " '900',\n",
       " '90210',\n",
       " '910',\n",
       " '911',\n",
       " '9116embed',\n",
       " '911s',\n",
       " '91embed',\n",
       " '92',\n",
       " '923',\n",
       " '93',\n",
       " '934',\n",
       " '94',\n",
       " '95',\n",
       " '950s',\n",
       " '95embed',\n",
       " '96',\n",
       " '96embed',\n",
       " '97',\n",
       " '98',\n",
       " '98embed',\n",
       " '99',\n",
       " '995',\n",
       " '9embed',\n",
       " '9mils',\n",
       " '9th',\n",
       " '9ths',\n",
       " 'a1',\n",
       " 'a3embed',\n",
       " 'a6s',\n",
       " 'a7s',\n",
       " 'aa',\n",
       " 'aaaaaah',\n",
       " 'aaaaahhhahah',\n",
       " 'aaaah',\n",
       " 'aaaahhahaaaahhhahaaaaaahhh',\n",
       " 'aaaall',\n",
       " 'aaaand',\n",
       " 'aaaarrgh',\n",
       " 'aaafro',\n",
       " 'aace',\n",
       " 'aah',\n",
       " 'aaieeahaaa',\n",
       " 'aak',\n",
       " 'aalegra',\n",
       " 'aaliyah',\n",
       " 'aand',\n",
       " 'aaoo',\n",
       " 'aap',\n",
       " 'aardappel',\n",
       " 'aaron',\n",
       " 'aastalled',\n",
       " 'aay',\n",
       " 'ab',\n",
       " 'ababababababa',\n",
       " 'ababy',\n",
       " 'aback',\n",
       " 'abad',\n",
       " 'abaht',\n",
       " 'abaiss√©',\n",
       " 'abaixar',\n",
       " 'abajo',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abandonment',\n",
       " 'abased',\n",
       " 'abashed',\n",
       " 'abba',\n",
       " 'abbattucci',\n",
       " 'abbels',\n",
       " 'abbess',\n",
       " 'abbey',\n",
       " 'abbo',\n",
       " 'abbot',\n",
       " 'abbreviation',\n",
       " 'abby',\n",
       " 'abb√©',\n",
       " 'abc',\n",
       " 'abcdefu',\n",
       " 'abcdpgc',\n",
       " 'abdicate',\n",
       " 'abdicated',\n",
       " 'abdication',\n",
       " 'abduction',\n",
       " 'abdul',\n",
       " 'abe',\n",
       " 'abeam',\n",
       " 'abed',\n",
       " 'abeg',\n",
       " 'abel',\n",
       " 'aberto',\n",
       " 'abeyance',\n",
       " 'abfalltree',\n",
       " 'abgod',\n",
       " 'abhor',\n",
       " 'abhorrent',\n",
       " 'abhors',\n",
       " 'abi',\n",
       " 'abide',\n",
       " 'abiding',\n",
       " 'abies',\n",
       " 'ability',\n",
       " 'abismo',\n",
       " 'abject',\n",
       " 'abjourned',\n",
       " 'abjuration',\n",
       " 'abjure',\n",
       " 'ablaze',\n",
       " 'able',\n",
       " 'ablitz',\n",
       " 'abloh',\n",
       " 'ablowing',\n",
       " 'ablukada',\n",
       " 'abnegand',\n",
       " 'abnegation',\n",
       " 'abnormal',\n",
       " 'abnormality',\n",
       " 'aboard',\n",
       " 'abode',\n",
       " 'abolish',\n",
       " 'abolished',\n",
       " 'abomasum',\n",
       " 'abominable',\n",
       " 'abominating',\n",
       " 'abomination',\n",
       " 'abortion',\n",
       " 'abounded',\n",
       " 'about203embed',\n",
       " 'aboutembed',\n",
       " 'aboutph√®dre',\n",
       " 'abra',\n",
       " 'abraabracadabra',\n",
       " 'abracadabra',\n",
       " 'abraham',\n",
       " 'abrams',\n",
       " 'abrasion',\n",
       " 'abrasive',\n",
       " 'abraxas',\n",
       " 'abridge',\n",
       " 'abridged',\n",
       " 'abril',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'abruptness',\n",
       " 'abscess',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absently',\n",
       " 'absentmindedness',\n",
       " 'absinthe',\n",
       " 'absofacto',\n",
       " 'absolete',\n",
       " 'absolut',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolution',\n",
       " 'absolved',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'absorbing',\n",
       " 'absorption',\n",
       " 'abstain',\n",
       " 'abstained',\n",
       " 'abstaining',\n",
       " 'abstention',\n",
       " 'abstinence',\n",
       " 'abstinent',\n",
       " 'abstract',\n",
       " 'abstracted',\n",
       " 'abstracting',\n",
       " 'abstraction',\n",
       " 'abstraxx',\n",
       " 'absurd',\n",
       " 'absurdity',\n",
       " 'absurdit√©s',\n",
       " 'absurdly',\n",
       " 'abu',\n",
       " 'abuela',\n",
       " 'abunda',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abundantly',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abusin',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'abustin',\n",
       " 'abutres',\n",
       " 'abutted',\n",
       " 'abyss',\n",
       " 'ac',\n",
       " 'acabando',\n",
       " 'acabar',\n",
       " 'acabaram',\n",
       " 'acabo',\n",
       " 'acaboembed',\n",
       " 'acab√≥',\n",
       " 'acacia',\n",
       " 'academe',\n",
       " 'academic',\n",
       " 'academician',\n",
       " 'academy',\n",
       " 'acad√©mie',\n",
       " 'acalled',\n",
       " 'acallin',\n",
       " 'acame',\n",
       " 'acan',\n",
       " 'acapella',\n",
       " 'acapulco',\n",
       " 'acarryin',\n",
       " 'accelerate',\n",
       " 'accelerated',\n",
       " 'accelerating',\n",
       " 'accelerator',\n",
       " 'accent',\n",
       " 'accents',\n",
       " 'accentuate',\n",
       " 'accentuated',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accessible',\n",
       " 'accessory',\n",
       " 'accesstopartnuzz',\n",
       " 'accidence',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'acclaim',\n",
       " 'acclamation',\n",
       " 'accolade',\n",
       " 'accommodating',\n",
       " 'accompanied',\n",
       " 'accompanies',\n",
       " 'accompaniment',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplice',\n",
       " 'accompliced',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'accomplishment',\n",
       " 'accord',\n",
       " 'accordance',\n",
       " 'accorded',\n",
       " 'accordin',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accordingto',\n",
       " 'accordion',\n",
       " 'accost',\n",
       " 'accostant',\n",
       " 'accosted',\n",
       " 'accosts',\n",
       " 'account',\n",
       " 'accountable',\n",
       " 'accountant',\n",
       " 'accounted',\n",
       " 'accourting',\n",
       " 'accredit',\n",
       " 'accredited',\n",
       " 'accretion',\n",
       " 'accrues',\n",
       " 'accumulate',\n",
       " 'accumulated',\n",
       " 'accumulates',\n",
       " 'accumulatin',\n",
       " 'accumulating',\n",
       " 'accumulation',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accursed',\n",
       " 'accusation',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accusin',\n",
       " 'accusing',\n",
       " 'accustomed',\n",
       " 'accwmwladed',\n",
       " 'acdc',\n",
       " 'ace',\n",
       " 'aceleran',\n",
       " 'acen',\n",
       " 'acende',\n",
       " 'aceno',\n",
       " 'acercando',\n",
       " 'acerco',\n",
       " 'acesas',\n",
       " 'ach',\n",
       " 'achal',\n",
       " 'achdung',\n",
       " 'ache',\n",
       " 'ached',\n",
       " 'acheivin',\n",
       " 'achewing',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achiever',\n",
       " 'achievin',\n",
       " 'achilles',\n",
       " 'achin',\n",
       " 'aching',\n",
       " 'achoo',\n",
       " 'achy',\n",
       " 'acid',\n",
       " 'acidic',\n",
       " 'acity',\n",
       " 'ack',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledging',\n",
       " 'acknowledgment',\n",
       " 'acne',\n",
       " 'acnomina',\n",
       " 'acome',\n",
       " 'acomin',\n",
       " 'acordado',\n",
       " 'acostumbre',\n",
       " 'acoustic',\n",
       " 'acquaintance',\n",
       " 'acquainted',\n",
       " 'acquainting',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquires',\n",
       " 'acquiring',\n",
       " 'acquisition',\n",
       " 'acquitted',\n",
       " 'acre',\n",
       " 'acreage',\n",
       " 'acrobatic',\n",
       " 'acrobatics',\n",
       " 'acronym',\n",
       " 'acropolis',\n",
       " 'acryin',\n",
       " 'act',\n",
       " 'acta',\n",
       " 'acted',\n",
       " 'acters',\n",
       " 'actin',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'activate',\n",
       " 'activated',\n",
       " 'activatin',\n",
       " 'active',\n",
       " 'activism',\n",
       " 'activist',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'actual',\n",
       " 'actuality',\n",
       " 'actually',\n",
       " 'actuated',\n",
       " 'actwho',\n",
       " 'acuerda',\n",
       " 'acuerdo',\n",
       " 'acupuncture',\n",
       " 'acura',\n",
       " 'acuras',\n",
       " 'acute',\n",
       " 'acutely',\n",
       " 'ac√°',\n",
       " 'ad',\n",
       " 'ada',\n",
       " 'adagio',\n",
       " 'adalbert',\n",
       " 'adam',\n",
       " 'adamant',\n",
       " 'adamelegy',\n",
       " 'adamlar',\n",
       " 'adamsoohoohooh',\n",
       " 'adapt',\n",
       " 'adaptability',\n",
       " 'adapted',\n",
       " 'adapting',\n",
       " 'adat',\n",
       " 'adazillahs',\n",
       " 'add',\n",
       " 'addams',\n",
       " 'added',\n",
       " 'adderall',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'addictive',\n",
       " 'addie',\n",
       " 'addin',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'addling',\n",
       " 'addonis',\n",
       " 'addonnis',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addressin',\n",
       " 'addressing',\n",
       " 'addurge',\n",
       " 'addy',\n",
       " 'adebesi',\n",
       " 'adekanbi',\n",
       " 'adekunle',\n",
       " 'adelante',\n",
       " 'adele',\n",
       " 'adelesucks',\n",
       " 'adeline',\n",
       " 'adenoid',\n",
       " 'adequate',\n",
       " 'adgigasta',\n",
       " 'adhd',\n",
       " 'adhere',\n",
       " 'adhered',\n",
       " 'adherence',\n",
       " 'adherent',\n",
       " 'adhering',\n",
       " 'adhesively',\n",
       " 'adidas',\n",
       " 'adieu',\n",
       " 'adina',\n",
       " 'adios',\n",
       " 'adioski',\n",
       " 'adi√≥s',\n",
       " 'adjacent',\n",
       " 'adjective',\n",
       " 'adjoining',\n",
       " 'adjured',\n",
       " 'adjust',\n",
       " 'adjusted',\n",
       " 'adjustin',\n",
       " 'adjusting',\n",
       " 'adjutant',\n",
       " 'adkins',\n",
       " 'adlib',\n",
       " 'administer',\n",
       " 'administered',\n",
       " 'administering',\n",
       " 'administration',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admirer',\n",
       " 'admires',\n",
       " 'admiring',\n",
       " 'admiringly',\n",
       " 'admissible',\n",
       " 'admission',\n",
       " 'admissions',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admitted',\n",
       " 'admitting',\n",
       " 'adnan',\n",
       " 'adnans',\n",
       " 'ado',\n",
       " 'adoin',\n",
       " 'adolescence',\n",
       " 'adolescent',\n",
       " 'adolphe',\n",
       " 'adolphes',\n",
       " 'adolphos',\n",
       " 'adonnis',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adopting',\n",
       " 'adoption',\n",
       " 'adopts',\n",
       " 'adorable',\n",
       " 'adoraci√≥n',\n",
       " 'adoration',\n",
       " 'adore',\n",
       " 'adored',\n",
       " 'adores',\n",
       " 'adoring',\n",
       " 'adorn',\n",
       " 'adorned',\n",
       " 'adornment',\n",
       " 'adrenalin',\n",
       " 'adrenaline',\n",
       " 'adrenalin–µ',\n",
       " 'adria',\n",
       " 'adrianople',\n",
       " 'adrienne',\n",
       " 'adrink',\n",
       " 'adroit',\n",
       " 'adroitly',\n",
       " 'adroitness',\n",
       " 'adsense',\n",
       " 'adu',\n",
       " 'adult',\n",
       " 'adultery',\n",
       " 'aduna',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantageous',\n",
       " 'advenements',\n",
       " 'adventure',\n",
       " 'adventurousness',\n",
       " 'adverb',\n",
       " 'adversary',\n",
       " 'adverse',\n",
       " 'adversely',\n",
       " 'adversity',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertiser',\n",
       " 'advertises',\n",
       " 'advertising',\n",
       " 'advica',\n",
       " 'advice',\n",
       " 'advil',\n",
       " 'advise',\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = cv.get_feature_names()\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Genre #0====================\n",
      "demonic üí© governor quantity known floridians gain jefferson visor tears closely medication bruised feb scary drs staked ing im jan lungs clots dealing ive whales hahaha mentions ho trending ecosys wannabe ‚Å† portrait base minimum uplifting acquire capital beginner unboxing notifications ist merchandise celebration Ï£º Ï¶à Î≥¥ Î¶¥ Í±∞ Ïßù\n",
      "\n",
      "====================Genre #1====================\n",
      "demonic üí© governor quantity known floridians gain jefferson visor tears closely medication bruised feb scary drs staked ing im jan lungs clots dealing ive whales hahaha mentions ho trending ecosys wannabe ‚Å† portrait base minimum uplifting acquire capital beginner unboxing notifications ist merchandise celebration Ï£º Ï¶à Î≥¥ Î¶¥ Í±∞ Ïßù\n",
      "\n",
      "====================Genre #2====================\n",
      "demonic üí© governor quantity known floridians gain jefferson visor tears closely medication bruised feb scary drs staked ing im jan lungs clots dealing ive whales hahaha mentions ho trending ecosys wannabe ‚Å† portrait base minimum uplifting acquire capital beginner unboxing notifications ist merchandise celebration Ï£º Ï¶à Î≥¥ Î¶¥ Í±∞ Ïßù\n",
      "\n",
      "====================Genre #3====================\n",
      "demonic üí© governor quantity known floridians gain jefferson visor tears closely medication bruised feb scary drs staked ing im jan lungs clots dealing ive whales hahaha mentions ho trending ecosys wannabe ‚Å† portrait base minimum uplifting acquire capital beginner unboxing notifications ist merchandise celebration Ï£º Ï¶à Î≥¥ Î¶¥ Í±∞ Ïßù\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#actually print top word per genre\n",
    "top_k_per_genre = lda.components_.argsort(axis=1)[:, -50:]\n",
    "for idx, genre in enumerate(top_k_per_genre):\n",
    "    print(\"=\" * 20 + f\"Genre #{idx}\" + \"=\" * 20)\n",
    "    print(encoder.decode(genre[::-1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
